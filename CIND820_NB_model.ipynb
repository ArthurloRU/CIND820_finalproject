{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: keras in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.7.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already up-to-date: tensorflow in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.7.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied, skipping upgrade: h5py>=2.9.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse>=1.6.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: gast<0.5.0,>=0.2.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers<3.0,>=1.12 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.21.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\losh\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.0 in c:\\users\\losh\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: keras<2.8,>=2.7.0rc0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard~=2.6 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.6 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel<1.0,>=0.32.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: libclang>=9.0.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (47.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\losh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras\n",
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, GRU\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "# from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "join_BID_tor_v2 = pd.read_csv('D:\\Ryerson\\CIND820\\Kaggle_yelp_dataset_CSV\\join_BID_tor_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_BID_tor_v2_samp = join_BID_tor_v2.sample(n = 20433 , random_state = 101)\n",
    "train = join_BID_tor_v2_samp[0:14000]\n",
    "test = join_BID_tor_v2_samp[14000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14000, 23), (6433, 23))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14421</th>\n",
       "      <td>I think it must be a great deal for meat eater...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>A beautiful, sunny day at The Beaches warrants...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>This is by far the best in its genre in the ci...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>I've been here about a handful of times and I'...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>Had dinner last night here and I have to say t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  stars_y\n",
       "14421  I think it must be a great deal for meat eater...        3\n",
       "1561   A beautiful, sunny day at The Beaches warrants...        4\n",
       "4163   This is by far the best in its genre in the ci...        5\n",
       "4623   I've been here about a handful of times and I'...        5\n",
       "6184   Had dinner last night here and I have to say t...        2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train[['text', 'stars_y']]\n",
    "train['stars_y'].hist();train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars_y_1</th>\n",
       "      <th>stars_y_2</th>\n",
       "      <th>stars_y_3</th>\n",
       "      <th>stars_y_4</th>\n",
       "      <th>stars_y_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14421</th>\n",
       "      <td>I think it must be a great deal for meat eater...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>A beautiful, sunny day at The Beaches warrants...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>This is by far the best in its genre in the ci...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>I've been here about a handful of times and I'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>Had dinner last night here and I have to say t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  stars_y_1  \\\n",
       "14421  I think it must be a great deal for meat eater...          0   \n",
       "1561   A beautiful, sunny day at The Beaches warrants...          0   \n",
       "4163   This is by far the best in its genre in the ci...          0   \n",
       "4623   I've been here about a handful of times and I'...          0   \n",
       "6184   Had dinner last night here and I have to say t...          0   \n",
       "\n",
       "       stars_y_2  stars_y_3  stars_y_4  stars_y_5  \n",
       "14421          0          1          0          0  \n",
       "1561           0          0          1          0  \n",
       "4163           0          0          0          1  \n",
       "4623           0          0          0          1  \n",
       "6184           1          0          0          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.get_dummies(train, columns = ['stars_y'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14000, 6), (6433, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = pd.read_csv('/home/adam/R/Yelp/dataset/model_test.csv', usecols=['text', 'stars'])\n",
    "test = test[['text', 'stars_y']]\n",
    "test = pd.get_dummies(test, columns = ['stars_y'])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frac = .33 to subsample in the initial trainings (to increase efficeny if needed)\n",
    "# train_samp = train.sample(frac = .33, random_state = 42)\n",
    "# test_samp = test.sample(frac = .33, random_state = 42)\n",
    "# train_samp.shape, test_samp.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features is an upper bound on the number of words in the vocabulary\n",
    "max_features = 2000\n",
    "tfidf = TfidfVectorizer(max_features = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBFeatures(BaseEstimator):\n",
    "    def __init__(self, alpha):\n",
    "        # Smoothing Parameter: always going to be one for my use\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def preprocess_x(self, x, r):\n",
    "        return x.multiply(r)\n",
    "    \n",
    "    # calculate probabilities\n",
    "    def pr(self, x, y_i, y):\n",
    "        p = x[y == y_i].sum(0)\n",
    "        return (p + self.alpha)/((y==y_i).sum()+self.alpha)\n",
    "    \n",
    "    # calculate the log ratio and represent as sparse matrix\n",
    "    # ie fit the nb model\n",
    "    def fit(self, x, y = None):\n",
    "        self._r = sparse.csr_matrix(np.log(self.pr(x, 1, y) /self.pr(x, 0, y)))\n",
    "        return self\n",
    "    \n",
    "    # apply the nb fit to original features x\n",
    "    def transform(self, x):\n",
    "        x_nb = self.preprocess_x(x, self._r)\n",
    "        return x_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline using sklearn pipeline:\n",
    "    # I basically create my tfidf features which are fed to my NB model \n",
    "    # for probability calculations. Then those are fed as input to my \n",
    "    # logistic regression model.\n",
    "lr = LogisticRegression()\n",
    "nb = NBFeatures(1)\n",
    "p = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('nb', nb),\n",
    "    ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class stars_y_1 is 0.9262857594551219\n",
      "CV score for class stars_y_2 is 0.904285677592131\n",
      "CV score for class stars_y_3 is 0.8329285952356656\n",
      "CV score for class stars_y_4 is 0.7001431194079487\n",
      "CV score for class stars_y_5 is 0.7929288805621716\n"
     ]
    }
   ],
   "source": [
    "class_names = ['stars_y_1', 'stars_y_2', 'stars_y_3', 'stars_y_4', 'stars_y_5']\n",
    "scores = []\n",
    "preds = np.zeros((len(test), len(class_names)))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    train_target = train[class_name]    \n",
    "    cv_score = np.mean(cross_val_score(estimator = p, X = train['text'].values, \n",
    "                                      y = train_target, cv = 3, scoring = 'accuracy'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    p.fit(train['text'].values, train_target)\n",
    "    preds[:,i] = p.predict_proba(test['text'].values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       684\n",
      "           1       0.45      0.14      0.22       576\n",
      "           2       0.51      0.35      0.41      1096\n",
      "           3       0.47      0.55      0.51      1974\n",
      "           4       0.64      0.76      0.69      2103\n",
      "\n",
      "    accuracy                           0.56      6433\n",
      "   macro avg       0.55      0.50      0.50      6433\n",
      "weighted avg       0.55      0.56      0.55      6433\n",
      "\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = metrics.classification_report(np.argmax(test[class_names].values, axis = 1),np.argmax(preds, axis = 1))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8307cd9af0e97630f8d6fae8fa8cf075c5a8326acb952193157434f24c616b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
